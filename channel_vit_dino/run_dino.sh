python -m torch.distributed.launch --nproc_per_node=8 main_dino.py --arch channelvit_small --data_path /scr/data/CHAMMI/chammi_train.zip --output_dir ./chammi_vit_testing --lr 0.00005 --batch_size_per_gpu 32 --dataset_size large --metadata ~/dataset/sampling/multi_channel_chammi_metadata.csv > log.txt
