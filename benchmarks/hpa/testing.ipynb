{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc94939",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.io import decode_image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9291a3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.Config.set_tbl_rows(-1)\n",
    "pl.Config.set_tbl_width_chars(-1)\n",
    "pl.Config.set_tbl_cols(-1)\n",
    "pl.Config.set_fmt_table_cell_list_len(-1)\n",
    "pl.Config.set_fmt_str_lengths(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca941a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = os.path.expanduser('/scr/data/cell_crops/')\n",
    "metadata_path = os.path.join(root_dir, 'metadata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4d02b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = pl.read_csv(metadata_path)\n",
    "first_entry = metadata[0]\n",
    "first_entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d021fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76ae14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_meta = metadata.rows(named=True)\n",
    "print(len(dict_meta))\n",
    "dict_meta[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e198c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40b5c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "studies = open(\"test_antibodies.txt\", 'r').readlines()\n",
    "studies = [s.strip() for s in studies if s.strip()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5d4dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_antibodies = metadata.filter(pl.col('antibody').is_in(studies))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059b87a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plate = str(first_entry['if_plate_id'].item())\n",
    "position = str(first_entry['position'].item())\n",
    "sample = str(first_entry['sample'].item())\n",
    "cell_id = sample = str(int(first_entry['cell_id'].item()))\n",
    "image = os.path.join(root_dir, plate, f\"{plate}_{position}_{sample}_{cell_id}_cell_image.png\")\n",
    "pask = os.path.join(root_dir, plate, f\"{plate}_{position}_{sample}_{cell_id}_cell_mask.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0781117",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3466cec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.io import decode_image\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "class UnZippedImageArchive(Dataset):\n",
    "    \"\"\"Basic unzipped image arch. This will no longer be used. \n",
    "       Remove when unzipped support is added to the IterableImageArchive\n",
    "    \"\"\"\n",
    "    def __init__(self, root_dir: str= '/scr/data/cell_crops/') -> None:\n",
    "        super().__init__()\n",
    "        self.root_dir = root_dir\n",
    "        self.metadata_path = os.path.join(self.root_dir, 'metadata.csv')\n",
    "        self.metadata = pl.read_csv(self.metadata_path).rows(named=True)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.metadata)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # microtubule fluorescence,  Blue (B) channel\n",
    "        # endoplasmic reticulum,  Green (G) channel\n",
    "        # DNA, Red (R) channel\n",
    "        # Protein of interest, Alpha (A) channel\n",
    "        # https://virtualcellmodels.cziscience.com/dataset/01933229-3c87-7818-be80-d7e5578bb0b7\n",
    "        row = self.metadata[idx]\n",
    "        plate = str(row['if_plate_id'])\n",
    "        position = row['position']\n",
    "        sample = str(row['sample'])\n",
    "        cell_id = str(int(row['cell_id']))\n",
    "        image = os.path.join(self.root_dir, plate, f\"{plate}_{position}_{sample}_{cell_id}_cell_image.png\")\n",
    "        image = decode_image(image, mode='RGBA'), decode_image(mask)\n",
    "        \n",
    "        # bool_mask = (mask>0).expand((image.shape[0], -1, -1))\n",
    "        # return torch.where(bool_mask, image, 0)\n",
    "        return image\n",
    "        \n",
    "dataset = UnZippedImageArchive()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e433d2d0",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'value'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m dataset \u001b[38;5;241m=\u001b[39m UnZippedImageArchive()\n\u001b[0;32m----> 2\u001b[0m image \u001b[38;5;241m=\u001b[39m \u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;66;03m# 4, 1024, 1024\u001b[39;00m\n\u001b[1;32m      4\u001b[0m channels \u001b[38;5;241m=\u001b[39m [channel\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m channel \u001b[38;5;129;01min\u001b[39;00m image]\n\u001b[1;32m      5\u001b[0m concatenated_image \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(channels[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "Cell \u001b[0;32mIn[11], line 35\u001b[0m, in \u001b[0;36mUnZippedImageArchive.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     33\u001b[0m image \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot_dir, plate, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mplate\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mposition\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msample\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcell_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_cell_image.png\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     34\u001b[0m mask \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot_dir, plate, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mplate\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mposition\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msample\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcell_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_cell_mask.png\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 35\u001b[0m image, mask \u001b[38;5;241m=\u001b[39m \u001b[43mdecode_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mRGBA\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m, decode_image(mask)\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# bool_mask = (mask>0).expand((image.shape[0], -1, -1))\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# return torch.where(bool_mask, image, 0)\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m image\n",
      "File \u001b[0;32m/scr/vidit/conda_env/lib/python3.10/site-packages/torchvision/io/image.py:236\u001b[0m, in \u001b[0;36mdecode_image\u001b[0;34m(input, mode)\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mis_scripting() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mis_tracing():\n\u001b[1;32m    235\u001b[0m     _log_api_usage_once(decode_image)\n\u001b[0;32m--> 236\u001b[0m output \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mops\u001b[38;5;241m.\u001b[39mimage\u001b[38;5;241m.\u001b[39mdecode_image(\u001b[38;5;28minput\u001b[39m, \u001b[43mmode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m)\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'value'"
     ]
    }
   ],
   "source": [
    "dataset = UnZippedImageArchive()\n",
    "image = dataset[5] # 4, 1024, 1024\n",
    "\n",
    "channels = [channel.unsqueeze(0) for channel in image]\n",
    "concatenated_image = torch.cat(channels[:-1], dim=0)\n",
    "image_data_rgb = np.transpose(concatenated_image, (1, 2, 0))\n",
    "\n",
    "image_data_rgb.shape\n",
    "plt.imshow(image_data_rgb)\n",
    "plt.axis('off')\n",
    "plt.savefig(f'full_slide_hpa.png', bbox_inches='tight', pad_inches=0)\n",
    "\n",
    "# for ch in range(concatenated_image.shape[0]):\n",
    "#     channel = concatenated_image[ch, : , :]\n",
    "#     plt.imshow(channel, cmap='grey')\n",
    "#     plt.axis('off')\n",
    "#     plt.savefig(f'ch_{ch}.png', bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff344950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available keys: ['all_features/data.pkl', 'all_features/data/0', 'all_features/version']\n",
      "data.pkl shape: No shape\n",
      "data/0 shape: No shape\n",
      "version: b'3\\n'\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Load the file\n",
    "load_features = np.load('/scr/data/HPA_features/all_features.pth')\n",
    "\n",
    "# See all available keys\n",
    "print(\"Available keys:\", list(load_features.keys()))\n",
    "\n",
    "# Access specific data using the keys\n",
    "data_pkl = load_features['all_features/data.pkl']\n",
    "data_0 = load_features['all_features/data/0']\n",
    "version = load_features['all_features/version']\n",
    "\n",
    "# Print shapes and types to understand the data\n",
    "print(f\"data.pkl shape: {data_pkl.shape if hasattr(data_pkl, 'shape') else 'No shape'}\")\n",
    "print(f\"data/0 shape: {data_0.shape if hasattr(data_0, 'shape') else 'No shape'}\")\n",
    "print(f\"version: {version}\")\n",
    "\n",
    "# Don't forget to close the file when done\n",
    "load_features.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a8f01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "features = torch.load('/scr/data/HPA_features/all_features.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e29e6af9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1138686, 14)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "metadata = pd.DataFrame(features[0])\n",
    "metadata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d3e69bbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1138688, 1536])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features[1].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50f58e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
