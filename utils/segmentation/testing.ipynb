{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from zipfile import ZipFile\n",
    "import polars as pl\n",
    "import torch\n",
    "from torchvision.io import decode_image\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "import torch.multiprocessing as mp\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "studies = pl.read_csv('./config.csv')['study'].unique().to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(studies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "OVERRIDES = {'experiment.well':pl.String, \n",
    "             'experiment.plate':pl.String, \n",
    "             'microscopy.fov': pl.String, \n",
    "             'microscopy.magnification': pl.String, \n",
    "             'geometry.depth': pl.String,\n",
    "             'geometry.z_slice': pl.String\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "polars.config.Config"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl.Config.set_tbl_rows(-1)\n",
    "pl.Config.set_tbl_width_chars(-1)\n",
    "pl.Config.set_tbl_cols(-1)\n",
    "pl.Config.set_fmt_table_cell_list_len(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1541257, 22)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta = pl.read_csv('~/dataset/sampling/75ds_small_meta.csv', schema_overrides=OVERRIDES)\n",
    "meta.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1430983, 22)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "substudies = meta.filter(pl.col('experiment.study').is_in(studies))\n",
    "substudies.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['75ds_small/idr0089/idr0089-plate_1A-converted/AC16_T18d24h_Rep1_PoorProbeChan1_Cry2Chan2_DAPIChan3_13_series-0_z-7_t-0_channel-0.png',\n",
       " '75ds_small/idr0089/idr0089-plate_1A-converted/AC16_T18d24h_Rep1_PoorProbeChan1_Cry2Chan2_DAPIChan3_14_series-0_z-7_t-0_channel-0.png',\n",
       " '75ds_small/idr0089/idr0089-plate_1A-converted/AC16_T18d24h_Rep1_PoorProbeChan1_Cry2Chan2_DAPIChan3_15_series-0_z-7_t-0_channel-0.png',\n",
       " '75ds_small/idr0089/idr0089-plate_1A-converted/AC16_T18d24h_Rep1_PoorProbeChan1_Cry2Chan2_DAPIChan3_2_series-0_z-7_t-0_channel-0.png',\n",
       " '75ds_small/idr0089/idr0089-plate_1A-converted/AC16_T18d24h_Rep1_PoorProbeChan1_Cry2Chan2_DAPIChan3_8_series-0_z-7_t-0_channel-0.png',\n",
       " '75ds_small/idr0089/idr0089-plate_1A-converted/AC16_T18d24h_Rep2_PoorProbeChan1_Cry2Chan2_DAPIChan3_1_series-0_z-7_t-0_channel-0.png',\n",
       " '75ds_small/idr0089/idr0089-plate_1A-converted/AC16_T18d24h_Rep2_PoorProbeChan1_Cry2Chan2_DAPIChan3_10_series-0_z-7_t-0_channel-0.png',\n",
       " '75ds_small/idr0089/idr0089-plate_1A-converted/AC16_T18d24h_Rep2_PoorProbeChan1_Cry2Chan2_DAPIChan3_2_series-0_z-7_t-0_channel-0.png',\n",
       " '75ds_small/idr0089/idr0089-plate_1A-converted/AC16_T18d24h_Rep2_PoorProbeChan1_Cry2Chan2_DAPIChan3_4_series-0_z-7_t-0_channel-0.png',\n",
       " '75ds_small/idr0089/idr0089-plate_1A-converted/AC16_T18d24h37d2h_Rep1_PoorProbeChan1_Cry2Chan2_DAPIChan3_11_series-0_z-7_t-0_channel-0.png']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "substudies.filter(pl.col('experiment.study') == 'idr0089')['storage.path'][:10].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = []\n",
    "base_path = os.path.expanduser('~/scratch/data/75ds_small_segmentations/')\n",
    "for path, _, files in os.walk(base_path):\n",
    "    paths = []\n",
    "    for file in files:\n",
    "        file_path = os.path.join(path.replace(base_path, ''), file)\n",
    "        paths.append(file_path.replace('.safetensors', '.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(680483, 22)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "262186"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class UnZippedImageArchive(Dataset):\n",
    "    \"\"\"Basic unzipped image arch. This will no longer be used. \n",
    "       Remove when unzipped support is added to the IterableImageArchive\n",
    "    \"\"\"\n",
    "    def __init__(self, output_path: str, overwrite: bool = False) -> None:\n",
    "        super().__init__()\n",
    "        self.overwrite = overwrite\n",
    "        self.output_path = os.path.expanduser(output_path)\n",
    "        self.configs: pl.DataFrame = pl.read_csv('./config.csv')\n",
    "        self.ds10 = self.configs['study'].unique().to_list()\n",
    "        self.configs = self.configs.to_pandas()\n",
    "        self.imgs_base = os.path.expanduser('/scr/data/75ds_small')\n",
    "        self.meta_path = os.path.expanduser(\"~/dataset/sampling/75ds_small_meta.csv\")\n",
    "        self.data = self.get_dataset()\n",
    "        self.size = self.data['imaging.multi_channel_id'].unique().len()\n",
    "        self.data = self.data.to_pandas().groupby('imaging.multi_channel_id')\n",
    "        self.data = [data for _, data in self.data]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.size\n",
    "        \n",
    "    def get_dataset(self):\n",
    "        meta = pl.read_csv(self.meta_path, schema_overrides=OVERRIDES)\n",
    "        meta = meta.sort('imaging.multi_channel_id').filter(pl.col('experiment.study').is_in(self.ds10))\n",
    "        if not self.overwrite:\n",
    "            base_path = self.output_path\n",
    "            paths = []\n",
    "            for path, _, files in os.walk(base_path):\n",
    "                for file in files:\n",
    "                    file_path = os.path.join(path.replace(base_path, ''), file)\n",
    "                    paths.append(file_path.replace('.safetensors', '.png'))\n",
    "                    \n",
    "        paths = set(paths)\n",
    "        meta = meta.filter(pl.col('storage.path').is_in(paths))\n",
    "        print(meta.shape)\n",
    "        return meta\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        data: pd.DataFrame = self.data[idx]\n",
    "        id = data['imaging.multi_channel_id'].iloc[0]\n",
    "        \n",
    "        data = data.sort_values('imaging.channel')\n",
    "        images_paths = [os.path.join(self.imgs_base, path) for path in data['storage.path'].to_list()]\n",
    "        \n",
    "        study = data['experiment.study'].iloc[0]       \n",
    "        channel_type = ','.join(data.sort_values('imaging.channel_type')['imaging.channel_type'].to_list())\n",
    "        channel_settings = self.configs[(self.configs['study'] == study) & (self.configs['config'] == channel_type)]\n",
    "        col_eq = channel_settings['seg_cfg'].iloc[0]\n",
    "        diameter = channel_settings['diameter'].iloc[0]\n",
    "        images = [decode_image(image)[0] for image in images_paths]\n",
    "    \n",
    "        image_data = {'id': id, 'study': [path for path in data['storage.path'].to_list()]}\n",
    "        if col_eq == \"classical\":\n",
    "            return images, image_data\n",
    "        elif col_eq == 'nucleus':\n",
    "            col_eq = int(data[data['imaging.channel_type'] == 'nucleus']['imaging.channel'].item())\n",
    "        elif col_eq == \"skip\":\n",
    "            image_data['config'] = col_eq\n",
    "            return images, image_data\n",
    "\n",
    "        col_eq = [col_eq] if isinstance(col_eq, int) else col_eq.split(',')\n",
    "        col_eq = [int(col) for col in col_eq]\n",
    "        \n",
    "        channel_axis = 1\n",
    "        if len(col_eq) == 2:\n",
    "                image_data['axis'] = channel_axis\n",
    "                channels_config = [1, 2]\n",
    "        else:\n",
    "            channel_axis = -1\n",
    "            channels_config = [0, 0]\n",
    "            \n",
    "        image_data['config'] = channels_config\n",
    "        image_data['diameter'] = diameter\n",
    "\n",
    "        if col_eq[0] != 0:\n",
    "            cellpose_images = [images[idx-1] for idx in col_eq]\n",
    "        else:\n",
    "            cellpose_images = images\n",
    "        \n",
    "        return cellpose_images, image_data\n",
    "    \n",
    "dataset = UnZippedImageArchive(os.path.expanduser('/scr/data/75ds_small_segmentations/'))\n",
    "len(dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "weakly-supervised",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
